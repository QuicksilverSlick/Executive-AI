<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Voice Agent Debug Panel</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        .panel {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .full-width {
            grid-column: 1 / -1;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        .connected { background-color: #d4edda; color: #155724; }
        .disconnected { background-color: #f8d7da; color: #721c24; }
        .connecting { background-color: #fff3cd; color: #856404; }
        .info { background-color: #d1ecf1; color: #0c5460; }
        button {
            padding: 10px 20px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            background-color: #007bff;
            color: white;
            cursor: pointer;
        }
        button:hover { background-color: #0056b3; }
        button:disabled { 
            background-color: #6c757d; 
            cursor: not-allowed; 
        }
        #logs {
            background-color: #2d2d2d;
            color: #f0f0f0;
            padding: 10px;
            border-radius: 5px;
            height: 400px;
            overflow-y: scroll;
            font-family: 'Courier New', monospace;
            font-size: 12px;
        }
        .log-error { color: #ff6b6b; }
        .log-success { color: #51cf66; }
        .log-warning { color: #ffd93d; }
        .log-info { color: #74c0fc; }
        .log-event { color: #ff8cc3; }
        .metrics {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 10px;
        }
        .metric {
            padding: 10px;
            background: #f0f0f0;
            border-radius: 5px;
        }
        .metric-label {
            font-size: 12px;
            color: #666;
        }
        .metric-value {
            font-size: 18px;
            font-weight: bold;
        }
        #audioVisualizer {
            width: 100%;
            height: 100px;
            background: #000;
            border-radius: 5px;
        }
        .event-monitor {
            max-height: 200px;
            overflow-y: auto;
            background: #f9f9f9;
            padding: 10px;
            border-radius: 5px;
            font-size: 12px;
        }
        .event-item {
            padding: 5px;
            margin: 2px 0;
            background: white;
            border-radius: 3px;
        }
    </style>
</head>
<body>
    <h1>WebRTC Voice Agent Debug Panel</h1>
    
    <div class="container">
        <!-- Connection Status Panel -->
        <div class="panel">
            <h2>Connection Status</h2>
            <div id="connectionStatus" class="status disconnected">Disconnected</div>
            <div id="conversationStatus" class="status info">Idle</div>
            <div class="metrics">
                <div class="metric">
                    <div class="metric-label">Token Status</div>
                    <div class="metric-value" id="tokenStatus">None</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Session ID</div>
                    <div class="metric-value" id="sessionId">None</div>
                </div>
                <div class="metric">
                    <div class="metric-label">ICE State</div>
                    <div class="metric-value" id="iceState">None</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Data Channel</div>
                    <div class="metric-value" id="dataChannelState">None</div>
                </div>
            </div>
        </div>

        <!-- Audio Status Panel -->
        <div class="panel">
            <h2>Audio Status</h2>
            <canvas id="audioVisualizer"></canvas>
            <div class="metrics">
                <div class="metric">
                    <div class="metric-label">Audio Level</div>
                    <div class="metric-value" id="audioLevel">0%</div>
                </div>
                <div class="metric">
                    <div class="metric-label">VAD Status</div>
                    <div class="metric-value" id="vadStatus">Inactive</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Local Tracks</div>
                    <div class="metric-value" id="localTracks">0</div>
                </div>
                <div class="metric">
                    <div class="metric-label">Remote Tracks</div>
                    <div class="metric-value" id="remoteTracks">0</div>
                </div>
            </div>
        </div>

        <!-- Control Panel -->
        <div class="panel full-width">
            <h2>Controls</h2>
            <button onclick="initializeAgent()">Initialize Agent</button>
            <button onclick="testResponse()">Test Response</button>
            <button onclick="sendTestMessage()">Send Text Message</button>
            <button onclick="manualResponse()">Manual Response Trigger</button>
            <button onclick="checkDataChannel()">Check Data Channel</button>
            <button onclick="checkAudioTracks()">Check Audio Tracks</button>
            <button onclick="clearLogs()">Clear Logs</button>
            <button onclick="downloadLogs()">Download Logs</button>
        </div>

        <!-- Event Monitor -->
        <div class="panel">
            <h2>Realtime Events</h2>
            <div id="eventMonitor" class="event-monitor"></div>
        </div>

        <!-- Transcripts -->
        <div class="panel">
            <h2>Transcripts</h2>
            <h4>User:</h4>
            <div id="userTranscript" style="background: #f0f0f0; padding: 10px; border-radius: 5px; min-height: 50px;"></div>
            <h4>Assistant:</h4>
            <div id="assistantTranscript" style="background: #f0f0f0; padding: 10px; border-radius: 5px; min-height: 50px;"></div>
        </div>

        <!-- Debug Logs -->
        <div class="panel full-width">
            <h2>Debug Logs</h2>
            <div id="logs"></div>
        </div>
    </div>

    <script>
        let voiceAgent = null;
        let allLogs = [];
        const logs = document.getElementById('logs');
        const eventMonitor = document.getElementById('eventMonitor');
        
        function log(message, type = 'info') {
            const timestamp = new Date().toISOString();
            const logEntry = { timestamp, message, type };
            allLogs.push(logEntry);
            
            const logElement = document.createElement('div');
            logElement.className = `log-${type}`;
            logElement.textContent = `[${timestamp}] ${message}`;
            logs.appendChild(logElement);
            logs.scrollTop = logs.scrollHeight;
            
            console.log(message);
        }
        
        function updateStatus(elementId, message, className) {
            const element = document.getElementById(elementId);
            if (element) {
                element.textContent = message;
                element.className = `status ${className}`;
            }
        }
        
        function updateMetric(elementId, value) {
            const element = document.getElementById(elementId);
            if (element) {
                element.textContent = value;
            }
        }
        
        function addEvent(event) {
            const eventItem = document.createElement('div');
            eventItem.className = 'event-item';
            eventItem.innerHTML = `<strong>${event.type}</strong>: ${JSON.stringify(event, null, 2).substring(0, 200)}...`;
            eventMonitor.insertBefore(eventItem, eventMonitor.firstChild);
            
            // Keep only last 20 events
            while (eventMonitor.children.length > 20) {
                eventMonitor.removeChild(eventMonitor.lastChild);
            }
        }
        
        async function initializeAgent() {
            try {
                log('Starting WebRTC Voice Agent initialization...', 'info');
                
                // Import the WebRTC Voice Agent class
                const module = await import('/src/lib/voice-agent/webrtc/main.ts');
                const WebRTCVoiceAgent = module.WebRTCVoiceAgent;
                
                // Create voice agent instance
                voiceAgent = new WebRTCVoiceAgent({
                    apiEndpoint: '/api/voice-agent',
                    features: {
                        continuousListening: true,
                        autoReconnect: true,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                // Set up comprehensive event handlers
                setupEventHandlers();
                
                // Initialize the agent
                await voiceAgent.initialize();
                
                log('Voice agent initialized successfully!', 'success');
                
                // Make it globally accessible for debugging
                window.voiceAgent = voiceAgent;
                
            } catch (error) {
                log(`Initialization failed: ${error.message}`, 'error');
                console.error(error);
            }
        }
        
        function setupEventHandlers() {
            // Connection events
            voiceAgent.on('connectionStateChanged', (state) => {
                log(`Connection state changed: ${state}`, 'event');
                updateStatus('connectionStatus', state, state === 'connected' ? 'connected' : state === 'connecting' ? 'connecting' : 'disconnected');
            });
            
            voiceAgent.on('conversationStateChanged', (state) => {
                log(`Conversation state changed: ${state}`, 'event');
                updateStatus('conversationStatus', state, 'info');
            });
            
            // Audio events
            voiceAgent.on('audioLevel', (level) => {
                updateMetric('audioLevel', `${Math.round(level * 100)}%`);
            });
            
            voiceAgent.on('speechStarted', () => {
                log('Speech started', 'event');
                updateMetric('vadStatus', 'Speaking');
            });
            
            voiceAgent.on('speechEnded', () => {
                log('Speech ended', 'event');
                updateMetric('vadStatus', 'Silent');
            });
            
            voiceAgent.on('playbackStarted', () => {
                log('Playback started', 'event');
            });
            
            voiceAgent.on('playbackFinished', () => {
                log('Playback finished', 'event');
            });
            
            // Transcript events
            voiceAgent.on('userTranscript', (data) => {
                log(`User transcript: ${data.text} (final: ${data.isFinal})`, 'info');
                document.getElementById('userTranscript').textContent = data.text;
            });
            
            voiceAgent.on('assistantTranscript', (data) => {
                log(`Assistant transcript: ${data.text} (final: ${data.isFinal})`, 'info');
                document.getElementById('assistantTranscript').textContent = data.text;
            });
            
            // Error events
            voiceAgent.on('error', (error) => {
                log(`Error: ${error.message} (${error.type})`, 'error');
            });
            
            voiceAgent.on('warning', (message) => {
                log(`Warning: ${message}`, 'warning');
            });
            
            // Monitor WebRTC connection
            if (voiceAgent.connection) {
                voiceAgent.connection.on('realtimeEvent', (event) => {
                    log(`Realtime event: ${event.type}`, 'event');
                    addEvent(event);
                });
                
                voiceAgent.connection.on('audioTrack', (stream) => {
                    log('Audio track received from OpenAI!', 'success');
                    updateMetric('remoteTracks', stream.getAudioTracks().length);
                });
                
                voiceAgent.connection.on('dataChannelOpen', () => {
                    log('Data channel opened!', 'success');
                    updateMetric('dataChannelState', 'Open');
                });
                
                voiceAgent.connection.on('dataChannelClose', () => {
                    log('Data channel closed', 'warning');
                    updateMetric('dataChannelState', 'Closed');
                });
            }
        }
        
        function testResponse() {
            if (voiceAgent && voiceAgent.testResponse) {
                log('Triggering test response...', 'info');
                voiceAgent.testResponse();
            } else {
                log('Voice agent not initialized or testResponse method not available', 'error');
            }
        }
        
        function sendTestMessage() {
            const message = prompt('Enter a test message:', 'Hello, can you hear me?');
            if (message && voiceAgent && voiceAgent.sendMessage) {
                log(`Sending message: "${message}"`, 'info');
                voiceAgent.sendMessage(message);
            }
        }
        
        function manualResponse() {
            if (voiceAgent && voiceAgent.connection) {
                log('Manually triggering response.create event...', 'info');
                
                // First create a user message
                const messageEvent = {
                    event_id: `manual_msg_${Date.now()}`,
                    type: 'conversation.item.create',
                    item: {
                        type: 'message',
                        role: 'user',
                        content: [{
                            type: 'input_text',
                            text: 'Please respond with voice. This is a test.'
                        }]
                    }
                };
                
                voiceAgent.connection.sendEvent(messageEvent);
                
                // Then trigger response
                setTimeout(() => {
                    const responseEvent = {
                        event_id: `manual_resp_${Date.now()}`,
                        type: 'response.create',
                        response: {
                            modalities: ['text', 'audio'],
                            instructions: 'Respond with a friendly greeting using voice.'
                        }
                    };
                    
                    voiceAgent.connection.sendEvent(responseEvent);
                    log('Response.create event sent', 'success');
                }, 500);
            }
        }
        
        function checkDataChannel() {
            if (voiceAgent && voiceAgent.connection && voiceAgent.connection.dataChannel) {
                const channel = voiceAgent.connection.dataChannel;
                log(`Data channel state: ${channel.readyState}`, 'info');
                log(`Data channel label: ${channel.label}`, 'info');
                log(`Data channel bufferedAmount: ${channel.bufferedAmount}`, 'info');
                updateMetric('dataChannelState', channel.readyState);
            } else {
                log('No data channel found', 'error');
            }
        }
        
        function checkAudioTracks() {
            if (voiceAgent && voiceAgent.connection && voiceAgent.connection.peerConnection) {
                const pc = voiceAgent.connection.peerConnection;
                
                // Check local tracks
                const senders = pc.getSenders();
                const localAudioTracks = senders.filter(s => s.track && s.track.kind === 'audio').length;
                log(`Local audio tracks: ${localAudioTracks}`, 'info');
                updateMetric('localTracks', localAudioTracks);
                
                // Check remote tracks
                const receivers = pc.getReceivers();
                const remoteAudioTracks = receivers.filter(r => r.track && r.track.kind === 'audio').length;
                log(`Remote audio tracks: ${remoteAudioTracks}`, 'info');
                updateMetric('remoteTracks', remoteAudioTracks);
                
                // Log track details
                receivers.forEach((receiver, index) => {
                    if (receiver.track && receiver.track.kind === 'audio') {
                        log(`Remote audio track ${index}: ${receiver.track.id}, state: ${receiver.track.readyState}, muted: ${receiver.track.muted}`, 'info');
                    }
                });
            } else {
                log('No peer connection found', 'error');
            }
        }
        
        function clearLogs() {
            logs.innerHTML = '';
            allLogs = [];
            log('Logs cleared', 'info');
        }
        
        function downloadLogs() {
            const logContent = allLogs.map(l => `[${l.timestamp}] [${l.type.toUpperCase()}] ${l.message}`).join('\n');
            const blob = new Blob([logContent], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `voice-agent-debug-${new Date().toISOString()}.log`;
            a.click();
            URL.revokeObjectURL(url);
        }
        
        // Setup audio visualizer
        function setupVisualizer() {
            const canvas = document.getElementById('audioVisualizer');
            const ctx = canvas.getContext('2d');
            canvas.width = canvas.offsetWidth;
            canvas.height = 100;
            
            function draw() {
                ctx.fillStyle = '#000';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                
                // Draw a simple waveform placeholder
                ctx.strokeStyle = '#0f0';
                ctx.beginPath();
                ctx.moveTo(0, canvas.height / 2);
                
                for (let i = 0; i < canvas.width; i++) {
                    const y = canvas.height / 2 + Math.sin(i * 0.02 + Date.now() * 0.001) * 20;
                    ctx.lineTo(i, y);
                }
                
                ctx.stroke();
                requestAnimationFrame(draw);
            }
            
            draw();
        }
        
        // Monitor peer connection stats
        function monitorPeerConnection() {
            setInterval(() => {
                if (voiceAgent && voiceAgent.connection && voiceAgent.connection.peerConnection) {
                    const pc = voiceAgent.connection.peerConnection;
                    updateMetric('iceState', pc.iceConnectionState);
                    
                    // Get connection info
                    const info = voiceAgent.connection.getConnectionInfo();
                    if (info.sessionId) {
                        updateMetric('sessionId', info.sessionId.substring(0, 8) + '...');
                    }
                }
            }, 1000);
        }
        
        // Initialize on load
        window.addEventListener('load', () => {
            setupVisualizer();
            monitorPeerConnection();
            
            // Override console methods to capture all logs
            const originalLog = console.log;
            const originalError = console.error;
            const originalWarn = console.warn;
            
            console.log = function(...args) {
                originalLog.apply(console, args);
                const message = args.map(a => typeof a === 'object' ? JSON.stringify(a) : a).join(' ');
                if (message.includes('[WebRTC') || message.includes('Realtime')) {
                    log(message, 'info');
                }
            };
            
            console.error = function(...args) {
                originalError.apply(console, args);
                const message = args.map(a => typeof a === 'object' ? JSON.stringify(a) : a).join(' ');
                log(message, 'error');
            };
            
            console.warn = function(...args) {
                originalWarn.apply(console, args);
                const message = args.map(a => typeof a === 'object' ? JSON.stringify(a) : a).join(' ');
                log(message, 'warning');
            };
        });
    </script>
</body>
</html>